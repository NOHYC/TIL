{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 코랩\n",
    "# 텐서플로우\n",
    "## pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras # 텐서플로우 코드를 좀 더 쉽게 작성할 수 있게 해주는 라이브러리 \n",
    "# 텐서플로우를 좀 더 쉽게 사용할 수 있게 해주는 추상화된 환경 \n",
    "#import tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자연어처리 패키지 : nltk, konlpy\n",
    "import nltk\n",
    "nltk.__version__ # 호환성 문제 때문에 버전을 확인해야한다. 잘 되던게 에러가 나는 경우가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do', \"n't\", 'After', 'preventing', 'President', 'Obama', \"'s\", 'from', 'filling', 'a', 'vacancy', 'four', 'years', 'ago', ',', 'Republicans', 'moved', 'swiftly', 'to', 'deliver', 'President', 'Trump', 'a', 'victory', 'days', 'before', 'the', 'election', '.', 'Both', 'presidential', 'candidates', 'campaigned', 'in', 'Pennsylvania', ',', 'where', 'Joe', 'Biden', 'said', 'he', 'would', 'expand', 'his', 'electoral', 'map', 'and', 'Mr.', 'Trump', 'mocked', 'Kamala', 'Harris', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(\"Don't After preventing President Obama's from filling a vacancy four years ago, Republicans moved swiftly to deliver President Trump a victory days before the election. Both presidential candidates campaigned in Pennsylvania, where Joe Biden said he would expand his electoral map and Mr. Trump mocked Kamala Harris.\"))\n",
    "# 'Do', \"n't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰? 자연어 처리 대상( 단위 : 문장, 단어, 문단...)\n",
    "# 토큰 : 문법적으로 더 이상 나눌 수 없는 요소 // 문장 단위도 토큰화 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', \"'\", 't', 'After', 'preventing', 'President', 'Obama', \"'\", 's', 'from', 'filling', 'a', 'vacancy', 'four', 'years', 'ago', ',', 'Republicans', 'moved', 'swiftly', 'to', 'deliver', 'President', 'Trump', 'a', 'victory', 'days', 'before', 'the', 'election', '.', 'Both', 'presidential', 'candidates', 'campaigned', 'in', 'Pennsylvania', ',', 'where', 'Joe', 'Biden', 'said', 'he', 'would', 'expand', 'his', 'electoral', 'map', 'and', 'Mr', '.', 'Trump', 'mocked', 'Kamala', 'Harris', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "print(WordPunctTokenizer().tokenize(\"Don't After preventing President Obama's from filling a vacancy four years ago, Republicans moved swiftly to deliver President Trump a victory days before the election. Both presidential candidates campaigned in Pennsylvania, where Joe Biden said he would expand his electoral map and Mr. Trump mocked Kamala Harris.\"))\n",
    "# 'Don', \"'\", 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"don't\", 'after', 'preventing', 'president', \"obama's\", 'from', 'filling', 'a', 'vacancy', 'four', 'years', 'ago', 'republicans', 'moved', 'swiftly', 'to', 'deliver', 'president', 'trump', 'a', 'victory', 'days', 'before', 'the', 'election', 'both', 'presidential', 'candidates', 'campaigned', 'in', 'pennsylvania', 'where', 'joe', 'biden', 'said', 'he', 'would', 'expand', 'his', 'electoral', 'map', 'and', 'mr', 'trump', 'mocked', 'kamala', 'harris']\n"
     ]
    }
   ],
   "source": [
    "print(text_to_word_sequence(\"Don't After preventing President Obama's from filling a vacancy four years ago, Republicans moved swiftly to deliver President Trump a victory days before the election. Both presidential candidates campaigned in Pennsylvania, where Joe Biden said he would expand his electoral map and Mr. Trump mocked Kamala Harris.\"))\n",
    "# \"don't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거 ?\n",
    "# 간혹 의미가 달라질 수 있음..\n",
    "# ex) $100 -> 100 의미가 불분명 : 기호 제거 시 생각해둘것\n",
    "# 영어 같은 경우 ' 기호를 많이 사용한다. => 줄임말을 전처리 과정에서 생각해줘야함 I'm => I am , what's -> what is \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 토큰화 \n",
    "# corpus( 코퍼스 )\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Don't After preventing Ph.D. Obama's from filling a vacancy four years ago. Republicans moved swiftly to deliver President Trump a victory days before the election. Both presidential candidates campaigned in Pennsylvania, where Joe Biden said he would expand his electoral map and Mr. Trump mocked Kamala Harris.\"\n",
    "# 점으로 문장을 구분한다. ago . \n",
    "# Ph.D. ??? 점으로 문장을 구분하지는 않는다!\n",
    "# .점이 들어가있는 몇몇 단어는 nltk가 구분할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Don't After preventing Ph.D. Obama's from filling a vacancy four years ago.\", 'Republicans moved swiftly to deliver President Trump a victory days before the election.', 'Both presidential candidates campaigned in Pennsylvania, where Joe Biden said he would expand his electoral map and Mr. Trump mocked Kamala Harris.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(text)) # 각각의 문장들이 홑따옴표로 묶여져있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어가 어려운 이유\n",
    "# 형태소 : 자립형태소(명사,감탄사...), 의존형태소(조사)\n",
    "# 띄어쓰기 : 지금이문장을해석하는데어려움이있나요? -> 띄어쓰기가 잘 안되어있음 \n",
    "# 지금 이 문장을 해석하는데 어려움이 있나요?\n",
    "# 품사에 따라 단어의 의미가 달라짐\n",
    "# mine : 지뢰, 광물을 캐다\n",
    "# 못 : 품사 태깅을 미리 수행하여, 특정 단어가 사용되기 앞서 어떤 품사로 사용되는지 구분(품사 태깅) tagging / natural language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['After', 'preventing', 'Ph.D.', 'Obama', \"'s\", 'from', 'filling', 'a', 'vacancy', 'four', 'years', 'ago', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \" After preventing Ph.D. Obama's from filling a vacancy four years ago.\"\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('After', 'IN'),\n",
       " ('preventing', 'VBG'),\n",
       " ('Ph.D.', 'NNP'),\n",
       " ('Obama', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('from', 'IN'),\n",
       " ('filling', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('vacancy', 'NN'),\n",
       " ('four', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('ago', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = word_tokenize(text)\n",
    "from nltk.tag import pos_tag\n",
    "pos_tag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kolnpy.org ( 태그 의미 )\n",
    "# https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0\n",
    "# nltk ( 태그 의미 )\n",
    "# https://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['열심히', '공부', '하고', '있는', '우리', '들', '.', '수료', '후', '에는', '취업', '에', '꼭', '성공해요']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석기(한국어)? 형태소 단위로 토큰화 한다는 의미\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "print(okt.morphs('열심히 공부하고 있는 우리들. 수료 후에는 취업에 꼭 성공해요'))\n",
    "# 형태소 단위로 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('열심히', 'Adverb'), ('공부', 'Noun'), ('하고', 'Josa'), ('있는', 'Adjective'), ('우리', 'Noun'), ('들', 'Suffix'), ('.', 'Punctuation'), ('수료', 'Noun'), ('후', 'Noun'), ('에는', 'Josa'), ('취업', 'Noun'), ('에', 'Josa'), ('꼭', 'Noun'), ('성공해요', 'Adjective')]\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos('열심히 공부하고 있는 우리들. 수료 후에는 취업에 꼭 성공해요'))\n",
    "# 형태소 단위로 품사 정보도 함께 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['공부', '우리', '수료', '후', '취업', '꼭']\n"
     ]
    }
   ],
   "source": [
    "print(okt.nouns('열심히 공부하고 있는 우리들. 수료 후에는 취업에 꼭 성공해요'))\n",
    "# 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['공부', '우리', '수료', '후', '취업', '성공']\n"
     ]
    }
   ],
   "source": [
    "km = Kkma()\n",
    "print(km.nouns('열심히 공부하고 있는 우리들. 수료 후에는 취업에 꼭 성공해요'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 자연어 전처리, 언어모델  \n",
    "2) 문서 단어벡터(tfidf). 문서자유도  \n",
    "3) 토픽 모델링  \n",
    "4) 머신러닝   \n",
    "5) Rnn -> LSTM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 마이닝 작업 중 데이터 정제\n",
    "# 데이터 정제 : 코퍼스(특정 도메인 단어들의 집합)로부터 노이즈 데이터 제거 \n",
    "# ex) 인공지능/ 법률 코퍼스  => 주제와 관련이 없는 단어들 : 노이즈\n",
    "# 정규화 : 동의어들 -> 같은 단어로 통합 \n",
    "# 불용어 제거 : 문맥상 의미가 없는 단어들 제거\n",
    "# 빈도수가 낮은 단어 제거 \n",
    "# 길이가 짧은 단어 제거\n",
    "\n",
    "# 정규표현식을 이용하여 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표제어 추출\n",
    "wnl.lemmatize('were')\n",
    "wnl.lemmatize('has','v')\n",
    "wnl.lemmatize('dies','v')\n",
    "wnl.lemmatize('watched','v') # 품사를 유지하면서 표제어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['live', 'go', 'do', 'love']\n"
     ]
    }
   ],
   "source": [
    "res =  [wnl.lemmatize(w,'v') for w in ['lives','going','doing','love']]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어간 추출(stemming)\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['After', 'preventing', 'President', 'Obama', \"'s\", 'from', 'filling', 'a', 'vacancy', 'four', 'years', 'ago', ',', 'Republicans', 'moved', 'swiftly', 'to', 'deliver', 'President', 'Trump', 'a', 'victory', 'days', 'before', 'the', 'election', '.', 'Both', 'presidential', 'candidates', 'campaigned', 'in', 'Pennsylvania', ',', 'where', 'Joe', 'Biden', 'said', 'he', 'would', 'expand', 'his', 'electoral', 'map', 'and', 'Mr.', 'Trump', 'mocked', 'Kamala', 'Harris', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \" After preventing President Obama's from filling a vacancy four years ago, Republicans moved swiftly to deliver President Trump a victory days before the election. Both presidential candidates campaigned in Pennsylvania, where Joe Biden said he would expand his electoral map and Mr. Trump mocked Kamala Harris.\"\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['after', 'prevent', 'presid', 'obama', \"'s\", 'from', 'fill', 'a', 'vacanc', 'four', 'year', 'ago', ',', 'republican', 'move', 'swiftli', 'to', 'deliv', 'presid', 'trump', 'a', 'victori', 'day', 'befor', 'the', 'elect', '.', 'both', 'presidenti', 'candid', 'campaign', 'in', 'pennsylvania', ',', 'where', 'joe', 'biden', 'said', 'he', 'would', 'expand', 'hi', 'elector', 'map', 'and', 'mr.', 'trump', 'mock', 'kamala', 'harri', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print([ps.stem(w) for w in words])\n",
    "# 포터 알고리즘에 의한 어간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aft', 'prev', 'presid', 'obam', \"'s\", 'from', 'fil', 'a', 'vac', 'four', 'year', 'ago', ',', 'republ', 'mov', 'swift', 'to', 'del', 'presid', 'trump', 'a', 'vict', 'day', 'bef', 'the', 'elect', '.', 'both', 'presid', 'candid', 'campaign', 'in', 'pennsylvan', ',', 'wher', 'joe', 'bid', 'said', 'he', 'would', 'expand', 'his', 'elect', 'map', 'and', 'mr.', 'trump', 'mock', 'kamal', 'har', '.']\n"
     ]
    }
   ],
   "source": [
    "print([ls.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어간 (stem) 어미 (ending)\n",
    "# 어간 : 긋다, 긋고,,, 잡다,잡고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = \"Family is not an important thing. Its everythong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "wt = word_tokenize(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "important\n",
      "thing\n",
      ".\n",
      "Its\n",
      "everythong\n"
     ]
    }
   ],
   "source": [
    "for w in wt: # wt 변수에 저장된 단어들읋 하나씩 읽어서 wt저장\n",
    "    if w not in sw: # w가 sw에 존재하지 않는다면 \n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ='텐서플로우와 머신러닝으로 자연어 처리를 하거든. 머신러닝으로만 자연어 처리를 하면 안돼.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = '어쨌든 아무거나 같다 비슷하다 하면 하거든 으로'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = sw.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['텐서플로우와',\n",
       " '머신러닝으로',\n",
       " '자연어',\n",
       " '처리를',\n",
       " '하거든',\n",
       " '.',\n",
       " '머신러닝으로만',\n",
       " '자연어',\n",
       " '처리를',\n",
       " '하면',\n",
       " '안돼',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt = word_tokenize(data)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for w in wt:\n",
    "    if w not in sw:\n",
    "        res.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['텐서플로우와', '머신러닝으로', '자연어', '처리를', '.', '머신러닝으로만', '자연어', '처리를', '안돼', '.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ranks.nl/stopwords/korean\n",
    "\n",
    "불용어 사전\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "전화번호 : 010-1234-5678\n",
    "주소 : 서울시 강남구\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['010', '1234', '5678']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\d+',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국 대한민국 코리아 korea 남한 고려'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '대한민국 한국 코리아 korea 남한 고려'\n",
    "re.sub('한국','대한민국',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Her impact could be felt right away. There are major election disputes awaiting immediate action by the Supreme Court from the battleground states of North Carolina and Pennsylvania. Both concern the date by which absentee ballots may be accepted. With Justice Barrett’s elevation in place of Justice Ginsburg, a liberal icon, the court is expected to tilt decisively to the right. It is gaining a conservative who could sway cases in every area of American life, including abortion rights, gay rights, business regulation and the environment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 토큰화\n",
    "text = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Her impact could be felt right away.',\n",
       " 'There are major election disputes awaiting immediate action by the Supreme Court from the battleground states of North Carolina and Pennsylvania.',\n",
       " 'Both concern the date by which absentee ballots may be accepted.',\n",
       " 'With Justice Barrett’s elevation in place of Justice Ginsburg, a liberal icon, the court is expected to tilt decisively to the right.',\n",
       " 'It is gaining a conservative who could sway cases in every area of American life, including abortion rights, gay rights, business regulation and the environment.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 크리닝, 단어 토큰화\n",
    "# 문장 -> 단어 -> 모두 소문자화 -> 불용어 제거 -> 짧은 길이의 단어 제거..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Beijing said Monday that it will impose sanctions on American companies — including Lockheed Martin, Boeing, and Raytheon — that have been involved in selling weapons to Taiwan.\n",
    "Speaking at a press conference Monday, Chinese Ministry of Foreign Affairs spokesperson Zhao Lijian called on the United States to stop selling arms to the self-governed island and to cut military ties with the government in Taipei.\n",
    "The sanctions are just the latest escalation in growing tensions between the United States and China over Taiwan. Even though the island has never been controlled by China's ruling Communist Party, Beijing insists it is an integral part of its territory and has threatened to use force if necessary to assert its control.\n",
    "\"We will continue to take necessary measures to safeguard national sovereignty and security interests,\" Zhao said. He reiterated that US arms sales to Taiwan \"seriously violate\" the one-China principle and harms China's security interests.\n",
    "The exact details of the sanctions have yet to be announced, but Zhao said they will apply to \"relevant US individuals and entities that played a negative role in the arms sales.\"\n",
    "Zhao specifically mentioned that the sanctions would affect major US companies such as Lockheed Martin (LMT), Boeing's (BA) defense contractor business, and Raytheon (RTN).\n",
    "US State Department spokeswoman Morgan Ortagus condemned China's threat of sanctions Monday night, saying that they were \"unproductive.\"\n",
    "\"We deplore Beijing's efforts to retaliate against US and foreign companies for their sales that support Taiwan's legitimate self-defense requirements, the necessity of which has been made abundantly clear through increasingly hostile incursions by [China's air force],\" she said.\n",
    "Boeing said the issue was one for governments to resolve.\n",
    "\"The US government decides on which defense systems to provide Taiwan and then makes the arrangements with the Department of Defense for the provision of such equipment,\" a Boeing spokesperson told CNN Business. \"Foreign military sales to any country or entity is a direct contractual obligation between the purchaser and the US government/Department of Defense.\"\n",
    "Lockheed Martin similarly said that foreign military sales are \"government-to-government transactions\" and emphasized that it works closely with US leadership.\n",
    "\"Lockheed Martin adheres to United States government policy with regard to conducting business with foreign governments,\" a spokesperson said. \"We do business with more than 70 nations around the world, and all of our international sales are strictly regulated by the US government.\"\n",
    "Raytheon did not immediately respond to a request for comment.\n",
    "In the past year, the Trump administration has moved to strengthen ties with Taipei, including increasing arms sales and facilitating high-level meetings between US and Taiwan officials.\n",
    "Last week the United States formally notified Congress of the proposed sale of three advanced weapons systems to Taiwan, totaling an estimated $1.8 billion. Just hours after Beijing threatened sanctions, the Trump administration notified Congress that it had approved a proposal for a $2.37 billion arms sale to Taiwan, which consisted of \"one hundred Harpoon Coastal Defense Systems.\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords =set(stopwords.words('english'))\n",
    "vocab = {}\n",
    "sentences = []\n",
    "for i in text:\n",
    "    sentence = word_tokenize(i)\n",
    "    res =[]\n",
    "    # print(sentence) # 단어\n",
    "    for word in sentence:\n",
    "        word = word.lower() # 소문자화\n",
    "        if word not in stopwords:\n",
    "            if len(word) > 2:\n",
    "                res.append(word)\n",
    "                if word not in vocab:\n",
    "                    vocab[word] =0 # word가 key, 0은 초기값 {'her': 0}\n",
    "                vocab[word] += 1 # {'her':1}\n",
    "    sentences.append(res)\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['beijing', 'said', 'monday', 'impose', 'sanctions', 'american', 'companies', 'including', 'lockheed', 'martin', 'boeing', 'raytheon', 'involved', 'selling', 'weapons', 'taiwan'], ['speaking', 'press', 'conference', 'monday', 'chinese', 'ministry', 'foreign', 'affairs', 'spokesperson', 'zhao', 'lijian', 'called', 'united', 'states', 'stop', 'selling', 'arms', 'self-governed', 'island', 'cut', 'military', 'ties', 'government', 'taipei'], ['sanctions', 'latest', 'escalation', 'growing', 'tensions', 'united', 'states', 'china', 'taiwan'], ['even', 'though', 'island', 'never', 'controlled', 'china', 'ruling', 'communist', 'party', 'beijing', 'insists', 'integral', 'part', 'territory', 'threatened', 'use', 'force', 'necessary', 'assert', 'control'], ['continue', 'take', 'necessary', 'measures', 'safeguard', 'national', 'sovereignty', 'security', 'interests', 'zhao', 'said'], ['reiterated', 'arms', 'sales', 'taiwan', 'seriously', 'violate', 'one-china', 'principle', 'harms', 'china', 'security', 'interests'], ['exact', 'details', 'sanctions', 'yet', 'announced', 'zhao', 'said', 'apply', 'relevant', 'individuals', 'entities', 'played', 'negative', 'role', 'arms', 'sales'], ['zhao', 'specifically', 'mentioned', 'sanctions', 'would', 'affect', 'major', 'companies', 'lockheed', 'martin', 'lmt', 'boeing', 'defense', 'contractor', 'business', 'raytheon', 'rtn'], ['state', 'department', 'spokeswoman', 'morgan', 'ortagus', 'condemned', 'china', 'threat', 'sanctions', 'monday', 'night', 'saying', 'unproductive'], ['deplore', 'beijing', 'efforts', 'retaliate', 'foreign', 'companies', 'sales', 'support', 'taiwan', 'legitimate', 'self-defense', 'requirements', 'necessity', 'made', 'abundantly', 'clear', 'increasingly', 'hostile', 'incursions', 'china', 'air', 'force', 'said'], ['boeing', 'said', 'issue', 'one', 'governments', 'resolve'], ['government', 'decides', 'defense', 'systems', 'provide', 'taiwan', 'makes', 'arrangements', 'department', 'defense', 'provision', 'equipment', 'boeing', 'spokesperson', 'told', 'cnn', 'business'], ['foreign', 'military', 'sales', 'country', 'entity', 'direct', 'contractual', 'obligation', 'purchaser', 'government/department', 'defense'], ['lockheed', 'martin', 'similarly', 'said', 'foreign', 'military', 'sales', 'government-to-government', 'transactions', 'emphasized', 'works', 'closely', 'leadership'], ['lockheed', 'martin', 'adheres', 'united', 'states', 'government', 'policy', 'regard', 'conducting', 'business', 'foreign', 'governments', 'spokesperson', 'said'], ['business', 'nations', 'around', 'world', 'international', 'sales', 'strictly', 'regulated', 'government'], ['raytheon', 'immediately', 'respond', 'request', 'comment'], ['past', 'year', 'trump', 'administration', 'moved', 'strengthen', 'ties', 'taipei', 'including', 'increasing', 'arms', 'sales', 'facilitating', 'high-level', 'meetings', 'taiwan', 'officials'], ['last', 'week', 'united', 'states', 'formally', 'notified', 'congress', 'proposed', 'sale', 'three', 'advanced', 'weapons', 'systems', 'taiwan', 'totaling', 'estimated', '1.8', 'billion'], ['hours', 'beijing', 'threatened', 'sanctions', 'trump', 'administration', 'notified', 'congress', 'approved', 'proposal', '2.37', 'billion', 'arms', 'sale', 'taiwan', 'consisted', 'one', 'hundred', 'harpoon', 'coastal', 'defense', 'systems']]\n",
      "{'beijing': 4, 'said': 7, 'monday': 3, 'impose': 1, 'sanctions': 6, 'american': 1, 'companies': 3, 'including': 2, 'lockheed': 4, 'martin': 4, 'boeing': 4, 'raytheon': 3, 'involved': 1, 'selling': 2, 'weapons': 2, 'taiwan': 8, 'speaking': 1, 'press': 1, 'conference': 1, 'chinese': 1, 'ministry': 1, 'foreign': 5, 'affairs': 1, 'spokesperson': 3, 'zhao': 4, 'lijian': 1, 'called': 1, 'united': 4, 'states': 4, 'stop': 1, 'arms': 5, 'self-governed': 1, 'island': 2, 'cut': 1, 'military': 3, 'ties': 2, 'government': 4, 'taipei': 2, 'latest': 1, 'escalation': 1, 'growing': 1, 'tensions': 1, 'china': 5, 'even': 1, 'though': 1, 'never': 1, 'controlled': 1, 'ruling': 1, 'communist': 1, 'party': 1, 'insists': 1, 'integral': 1, 'part': 1, 'territory': 1, 'threatened': 2, 'use': 1, 'force': 2, 'necessary': 2, 'assert': 1, 'control': 1, 'continue': 1, 'take': 1, 'measures': 1, 'safeguard': 1, 'national': 1, 'sovereignty': 1, 'security': 2, 'interests': 2, 'reiterated': 1, 'sales': 7, 'seriously': 1, 'violate': 1, 'one-china': 1, 'principle': 1, 'harms': 1, 'exact': 1, 'details': 1, 'yet': 1, 'announced': 1, 'apply': 1, 'relevant': 1, 'individuals': 1, 'entities': 1, 'played': 1, 'negative': 1, 'role': 1, 'specifically': 1, 'mentioned': 1, 'would': 1, 'affect': 1, 'major': 1, 'lmt': 1, 'defense': 5, 'contractor': 1, 'business': 4, 'rtn': 1, 'state': 1, 'department': 2, 'spokeswoman': 1, 'morgan': 1, 'ortagus': 1, 'condemned': 1, 'threat': 1, 'night': 1, 'saying': 1, 'unproductive': 1, 'deplore': 1, 'efforts': 1, 'retaliate': 1, 'support': 1, 'legitimate': 1, 'self-defense': 1, 'requirements': 1, 'necessity': 1, 'made': 1, 'abundantly': 1, 'clear': 1, 'increasingly': 1, 'hostile': 1, 'incursions': 1, 'air': 1, 'issue': 1, 'one': 2, 'governments': 2, 'resolve': 1, 'decides': 1, 'systems': 3, 'provide': 1, 'makes': 1, 'arrangements': 1, 'provision': 1, 'equipment': 1, 'told': 1, 'cnn': 1, 'country': 1, 'entity': 1, 'direct': 1, 'contractual': 1, 'obligation': 1, 'purchaser': 1, 'government/department': 1, 'similarly': 1, 'government-to-government': 1, 'transactions': 1, 'emphasized': 1, 'works': 1, 'closely': 1, 'leadership': 1, 'adheres': 1, 'policy': 1, 'regard': 1, 'conducting': 1, 'nations': 1, 'around': 1, 'world': 1, 'international': 1, 'strictly': 1, 'regulated': 1, 'immediately': 1, 'respond': 1, 'request': 1, 'comment': 1, 'past': 1, 'year': 1, 'trump': 2, 'administration': 2, 'moved': 1, 'strengthen': 1, 'increasing': 1, 'facilitating': 1, 'high-level': 1, 'meetings': 1, 'officials': 1, 'last': 1, 'week': 1, 'formally': 1, 'notified': 2, 'congress': 2, 'proposed': 1, 'sale': 2, 'three': 1, 'advanced': 1, 'totaling': 1, 'estimated': 1, '1.8': 1, 'billion': 2, 'hours': 1, 'approved': 1, 'proposal': 1, '2.37': 1, 'consisted': 1, 'hundred': 1, 'harpoon': 1, 'coastal': 1}\n"
     ]
    }
   ],
   "source": [
    "print(sentences)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
    "# 특정 분야에 코퍼스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 1,\n",
       " 'secret': 2,\n",
       " 'huge': 3,\n",
       " 'kept': 4,\n",
       " 'person': 5,\n",
       " 'word': 6,\n",
       " 'keeping': 7,\n",
       " 'good': 8,\n",
       " 'knew': 9,\n",
       " 'driving': 10,\n",
       " 'crazy': 11,\n",
       " 'went': 12,\n",
       " 'mountain': 13}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(sentences) \n",
    "# tokenizer.fit_on_texts(코퍼스) : 코퍼스에 등장하는 단어들에 대한 빈도수를 기준으로 단어 집합 생성\n",
    "# 빈도수가 높은 ~ 낮은 단어 순으로 번호를 부여. 확인은 word_index\n",
    "tokenizer.word_index # 빈도순으로 출력 index 1 가장 빈번한 barber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('barber', 8),\n",
       "             ('person', 3),\n",
       "             ('good', 1),\n",
       "             ('huge', 5),\n",
       "             ('knew', 1),\n",
       "             ('secret', 6),\n",
       "             ('kept', 4),\n",
       "             ('word', 2),\n",
       "             ('keeping', 2),\n",
       "             ('driving', 1),\n",
       "             ('crazy', 1),\n",
       "             ('went', 1),\n",
       "             ('mountain', 1)])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 8, 5],\n",
       " [1, 3, 5],\n",
       " [9, 2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4, 6],\n",
       " [1, 4, 6],\n",
       " [1, 4, 2],\n",
       " [7, 7, 3, 2, 10, 1, 11],\n",
       " [1, 12, 3, 13]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(sentences)\n",
    "# 각 단어별 인덱스 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = 5 # 빈도수가 높은 5개 단어만 추출\n",
    "tokenizer = Tokenizer(num_words=vs+1)\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 1,\n",
       " 'secret': 2,\n",
       " 'huge': 3,\n",
       " 'kept': 4,\n",
       " 'person': 5,\n",
       " 'word': 6,\n",
       " 'keeping': 7,\n",
       " 'good': 8,\n",
       " 'knew': 9,\n",
       " 'driving': 10,\n",
       " 'crazy': 11,\n",
       " 'went': 12,\n",
       " 'mountain': 13}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('barber', 8),\n",
       "             ('person', 3),\n",
       "             ('good', 1),\n",
       "             ('huge', 5),\n",
       "             ('knew', 1),\n",
       "             ('secret', 6),\n",
       "             ('kept', 4),\n",
       "             ('word', 2),\n",
       "             ('keeping', 2),\n",
       "             ('driving', 1),\n",
       "             ('crazy', 1),\n",
       "             ('went', 1),\n",
       "             ('mountain', 1)])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 5],\n",
       " [1, 3, 5],\n",
       " [2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4],\n",
       " [1, 4],\n",
       " [1, 4, 2],\n",
       " [3, 2, 1],\n",
       " [1, 3]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
