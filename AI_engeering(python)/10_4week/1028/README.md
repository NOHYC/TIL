# 1028

## 자연어 처리

### 딕셔너리 타입 sort

데이터 타입 딕셔너리

sorted( 데이터.items() ,key = lambda x: x[1] ) 

> 딕셔너리 타입 데이터에 items() 함수 대입하면
>
> 튜플 형태로 반환된다. ( ' key ' , value ) 이런 식
>
> 정렬을 첫번째 인수가 아닌 두번째 값으로 할 수 있는데 
>
> 이때 이용하는 옵션이 key 다. 
>
> key 옵션은 함수로 적을 수 있기 때문에 lambda x: x[1] 
>
> 사용하여 두번째 값 기준으로 정렬할 수 있다.

### from collections import Counter

- vocab = Counter(words) 
- 리스트에 있는 단어의 개수를 세서 **딕셔너리** 형태로 반환

```
Counter({'barber': 8,
         'person': 3,
         'good': 1,
         'huge': 5,
         'knew': 1,
         'secret': 6,
         'kept': 4,
         'word': 2,
         'keeping': 2,
         'driving': 1,
         'crazy': 1,
         'went': 1,
         'mountain': 1})
```

- 가장 많이 등장한 단어 추출
- vocab.most_common(vs)

```
[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]
```



#### 위 방법을 nltk 라이브러리로 구현

#### from nltk import FreqDist

```
FreqDist(np.hstack(sentences))
```

```
FreqDist({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, ...})
```







### corupus

#### OOV : 코퍼스(말뭉치) 에 없는 단어 집합이다.

- 6번째 값

```
{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'OOV': 6}
```

### 토큰화되어 있는 2차원 리스트를 1차원 리스트로 변경

 #### sum(토큰화 리스트, [])

#### np.hstack(토큰화 리스트)



### 패딩 

> 문장의 길이가 다르기 때문에 연산에서 문제가 생긴다.
>
> 문장길이 일치 작업

#### from tensorflow.keras.preprocessing.sequence import pad_sequences

- pad_sequences(**인덱스 토큰화된 2차원리스트**) 
- default는 0을 앞에서 부터 채운다.

```
array([[ 0,  0,  0,  0,  0,  1,  5],
       [ 0,  0,  0,  0,  1,  8,  5],
       [ 0,  0,  0,  0,  1,  3,  5],
       [ 0,  0,  0,  0,  0,  9,  2],
       [ 0,  0,  0,  2,  4,  3,  2],
       [ 0,  0,  0,  0,  0,  3,  2],
       [ 0,  0,  0,  0,  1,  4,  6],
       [ 0,  0,  0,  0,  1,  4,  6],
       [ 0,  0,  0,  0,  1,  4,  2],
       [ 7,  7,  3,  2, 10,  1, 11],
       [ 0,  0,  0,  1, 12,  3, 13]])
```

- padding = 'post' 옵션을 주면 0을 뒤에서 부터 채운다.

```
array([[ 1,  5,  0,  0,  0,  0,  0],
       [ 1,  8,  5,  0,  0,  0,  0],
       [ 1,  3,  5,  0,  0,  0,  0],
       [ 9,  2,  0,  0,  0,  0,  0],
       [ 2,  4,  3,  2,  0,  0,  0],
       [ 3,  2,  0,  0,  0,  0,  0],
       [ 1,  4,  6,  0,  0,  0,  0],
       [ 1,  4,  6,  0,  0,  0,  0],
       [ 1,  4,  2,  0,  0,  0,  0],
       [ 7,  7,  3,  2, 10,  1, 11],
       [ 1, 12,  3, 13,  0,  0,  0]])
```

- maxlen = 5 옵션을 주면 데이터 리스트 길이를 5로 줄인다.

```
array([[ 1,  5,  0,  0,  0],
       [ 1,  8,  5,  0,  0],
       [ 1,  3,  5,  0,  0],
       [ 9,  2,  0,  0,  0],
       [ 2,  4,  3,  2,  0],
       [ 3,  2,  0,  0,  0],
       [ 1,  4,  6,  0,  0],
       [ 1,  4,  6,  0,  0],
       [ 1,  4,  2,  0,  0],
       [ 3,  2, 10,  1, 11],
       [ 1, 12,  3, 13,  0]])
```





# 자연어 처리

## 자연어 처리과정

### 자연어 집합 -> 정수 인코딩 -> 원핫 인코딩

#### 원핫 인코딩

- from **tensorflow.keras.utils** import **to_categorical**

> 원핫 인코딩을 하기까지 정수인코딩 과정을 거쳐야한다.
>
> 토큰화(Tokenizer) -> 코퍼스(fit_on_texts) -> 정수 인코딩(texts_to_sequences) 

- oh = to_categorical(encoded)

```
array([[0., 0., 0., 0., 0., 1., 0.],
       [0., 1., 0., 0., 0., 0., 0.],
       [0., 0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1.]], dtype=float32)
```

