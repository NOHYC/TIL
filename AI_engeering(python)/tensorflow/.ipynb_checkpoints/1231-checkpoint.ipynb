{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우는 edges와 nodes로 구조화된 graph로 구성\n",
    "# 빌딩 구조와 실행 구조(session)로 처리 순서\n",
    "import tensorflow.compat.v1 as tf # 텐서플로우 버전 1 사용\n",
    "tf.disable_v2_behavior() # 텐서플로우 1버전만 사용하겠다\n",
    "x = tf.constant(35,name='x') # 상수\n",
    "y = tf.Variable(x + 5, name = 'y') # 변수\n",
    "\n",
    "model = tf.global_variables_initializer() # 변수 초기화\n",
    "\n",
    "with tf.Session() as sess: # 세션 만들기\n",
    "    sess.run(model) # 초기화 실행\n",
    "    print(sess.run(y)) # 변수 y 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"linspace/Slice:0\", shape=(10,), dtype=float32)\n",
      "['x', 'add/y', 'add', 'y', 'y/IsInitialized/VarIsInitializedOp', 'y/Assign', 'y/Read/ReadVariableOp', 'x_1', 'add_1/y', 'add_1', 'y_1', 'y_1/IsInitialized/VarIsInitializedOp', 'y_1/Assign', 'y_1/Read/ReadVariableOp', 'x_2', 'add_2/y', 'add_2', 'y_2', 'y_2/IsInitialized/VarIsInitializedOp', 'y_2/Assign', 'y_2/Read/ReadVariableOp', 'x_3', 'add_3/y', 'add_3', 'y_3', 'y_3/IsInitialized/VarIsInitializedOp', 'y_3/Assign', 'y_3/Read/ReadVariableOp', 'x_4', 'add_4/y', 'add_4', 'y_4', 'y_4/Assign', 'y_4/read', 'init', 'x_5', 'add_5/y', 'add_5', 'y_5', 'y_5/Assign', 'y_5/read', 'init_1', 'x_6', 'add_6/y', 'add_6', 'y_6', 'y_6/Assign', 'y_6/read', 'init_2', 'linspace/start', 'linspace/stop', 'linspace/num', 'linspace/Cast', 'linspace/Cast_1', 'linspace/Shape', 'linspace/Shape_1', 'linspace/BroadcastArgs', 'linspace/BroadcastTo', 'linspace/BroadcastTo_1', 'linspace/ExpandDims/dim', 'linspace/ExpandDims', 'linspace/ExpandDims_1/dim', 'linspace/ExpandDims_1', 'linspace/Shape_2', 'linspace/Shape_3', 'linspace/strided_slice/stack', 'linspace/strided_slice/stack_1', 'linspace/strided_slice/stack_2', 'linspace/strided_slice', 'linspace/add/y', 'linspace/add', 'linspace/SelectV2/condition', 'linspace/SelectV2/t', 'linspace/SelectV2', 'linspace/sub/y', 'linspace/sub', 'linspace/Maximum/y', 'linspace/Maximum', 'linspace/sub_1/y', 'linspace/sub_1', 'linspace/Maximum_1/y', 'linspace/Maximum_1', 'linspace/sub_2', 'linspace/Cast_2', 'linspace/truediv', 'linspace/GreaterEqual/y', 'linspace/GreaterEqual', 'linspace/SelectV2_1/e', 'linspace/SelectV2_1', 'linspace/range/start', 'linspace/range/delta', 'linspace/range/Cast', 'linspace/range', 'linspace/Cast_3', 'linspace/range_1/start', 'linspace/range_1/delta', 'linspace/range_1', 'linspace/Equal', 'linspace/SelectV2_2/e', 'linspace/SelectV2_2', 'linspace/Reshape', 'linspace/mul', 'linspace/add_1', 'linspace/concat', 'linspace/zeros_like', 'linspace/SelectV2_3', 'linspace/Slice']\n",
      "[-1.         -0.7777778  -0.5555556  -0.3333333  -0.1111111   0.11111116\n",
      "  0.33333337  0.5555556   0.7777778   1.        ]\n"
     ]
    }
   ],
   "source": [
    "x2 = tf.linspace(-1.0,1.0,10)\n",
    "print(x2) # Tensor(\"linspace/Slice:0\", shape=(10,), dtype=float32) 구조만 출력\n",
    "\n",
    "g = tf.get_default_graph()\n",
    "print([op.name for op in g.get_operations()])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x2)) # 실행 결과 출력\n",
    "# [-1.         -0.7777778  -0.5555556  -0.3333333  -0.1111111   0.11111116\n",
    "#   0.33333337  0.5555556   0.7777778   1.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 텐서 플로우 실행 구조\n",
    "# Feed (placeholder에 값 대입) -> graph -> Fetch( 연산 결과를 가져온다 )\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1,input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output] , feed_dict ={input1:[7.],input2:[2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'y_22:0' shape=() dtype=int32_ref>\n",
      "<tf.Variable 'y_23:0' shape=(2,) dtype=int32_ref>\n",
      "y_23:0\n",
      "<bound method RefVariable.value of <tf.Variable 'y_23:0' shape=(2,) dtype=int32_ref>>\n",
      "<dtype: 'int32_ref'>\n"
     ]
    }
   ],
   "source": [
    "# 변수 정의\n",
    "# 변수정의는 tf.Variable()를 이용해서 초기값과 변수명을 정의\n",
    "# 변수는 그래프 실행 시, 파라미터를 저장하고 갱신하는데 사용되며 메모리 상에서는 텐서를 저장하는 버퍼 역할을 함\n",
    "x = tf.constant(35,name = 'x')\n",
    "y = tf.Variable(x+5,name = 'y')\n",
    "print(y) # 객체만 나타난다\n",
    "\n",
    "y = tf.Variable([5,5],name = 'y')\n",
    "print(y)\n",
    "print(y.name) # y_9:0\n",
    "print(y.value) # <bound method RefVariable.value of <tf.Variable 'y_9:0' shape=(2,) dtype=int32_ref>>\n",
    "print(y.dtype) # <dtype: 'int32_ref'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_16:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_3:0\", shape=(2, 2), dtype=float32)\n",
      "[1.0, 2.0]\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[3.0]\n",
      "[[2. 3.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# 상수 노드 constant\n",
    "# 상수 노드 정의\n",
    "a = tf.constant(1.0,name = 'a')\n",
    "b = tf.constant(2.0,name = 'b')\n",
    "c = tf.constant([ [1.0,2.0],[3.0,4.0]])\n",
    "\n",
    "# 세선을 만들지 않고 print 같은 명령문을 실행하면 \n",
    "# 저장된 값이 아난 현재 정의되어 있는 노드의 상태( 노드 타입, shape 등)가 출력됨\n",
    "print(a)\n",
    "print(a+b)\n",
    "print(c)\n",
    "\n",
    "# 세션을 만들고 노드간 텐서 연산 실행\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([a,b]))\n",
    "    print(sess.run(c))\n",
    "    print(sess.run([a+b]))\n",
    "    print(sess.run(c+1.0)) # 브로드캐스팅\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "[4. 6.]\n",
      "400.0\n",
      "[400. 600.]\n"
     ]
    }
   ],
   "source": [
    "# 입의의 입력값을 받을 수 있는 placeholder 노드\n",
    "# 플레이스홀더 노드는 머신러닝/딥러닝에서 입력데이터(input) 정답 데이터(target)를 넣어주기 위한 용도로 주로 사용됨\n",
    "\n",
    "a = tf.placeholder(tf.float32) # 입력으로 받을 데이터 타입 정의\n",
    "b = tf.placeholder(tf.float32) # 입력으로 받을 데이터 타입 정의\n",
    "c = a+b\n",
    "\n",
    "# 세션을 만들고 플레이스홀더 노드를 통해 값을 입력 받음\n",
    "with tf.Session() as sess:\n",
    "    # 플레이스 홀더 노드에 실제값을 넣어줄 때 sess.run 첫번째 인자로 연산을 넣고, 두번째 인자에는 실제 값을 딕셔너리형태로 넣어준다\n",
    "    # 넣어 줄때는 feed_dict ={} \n",
    "    print(sess.run(c,feed_dict={a:1.0,b:3.0}))\n",
    "    print(sess.run(c,feed_dict={a:[1.0,2.0],b:[3.0,4.0]}))\n",
    "    \n",
    "    d = 100*c\n",
    "    \n",
    "    print(sess.run(d,feed_dict={a:1.0,b:3.0}))\n",
    "    print(sess.run(d,feed_dict={a:[1.0,2.0],b:[3.0,4.0]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 ,w1 =  [-0.36935166] ,b1 =  [-0.51327306]\n",
      "step = 0 ,w1 =  [[ 0.34768933 -0.93606156]] ,b2 =  [[-0.9735673   0.22157076]]\n",
      "step = 1 ,w1 =  [-1.3693516] ,b1 =  [-1.513273]\n",
      "step = 1 ,w1 =  [[-0.65231067 -1.9360616 ]] ,b2 =  [[-1.9735672  -0.77842927]]\n",
      "step = 2 ,w1 =  [-3.3693516] ,b1 =  [-3.513273]\n",
      "step = 2 ,w1 =  [[-2.6523106 -3.9360616]] ,b2 =  [[-3.9735672 -2.7784293]]\n"
     ]
    }
   ],
   "source": [
    "# 변수를 저장하는 variable 노드\n",
    "# 가중치나 바이어스처럼 계속 업데이트되는 변수는 텐서플로우에서 변수 노드로 정의\n",
    "# tf.Variable 에서 사용되는 초기값\n",
    "# tf.random_normal , tf.truncated_normal\n",
    "# tf.random_uniform, tf.ones tf.zeros, tf.constant 등이 있음\n",
    "w1 = tf.Variable(tf.random_normal([1])) # w1 = np.random.rand(1) 과 비슷함\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([1,2])) \n",
    "b2 = tf.Variable(tf.random_normal([1,2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 변수 노드 값 초기화 ==> 변수 노드를 정의했다면 반드시 필요함\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(3):\n",
    "        # w, b 변수노드 업데이트\n",
    "        w1 = w1 - step\n",
    "        b1 = b1 - step\n",
    "        \n",
    "        w2 = w2 - step\n",
    "        b2 = b2 - step\n",
    "        print('step =',step,',w1 = ',sess.run(w1),',b1 = ',sess.run(b1))\n",
    "        print('step =',step,',w1 = ',sess.run(w2),',b2 = ',sess.run(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강의 출처 : https://www.youtube.com/watch?v=KGUw4_NE__s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
